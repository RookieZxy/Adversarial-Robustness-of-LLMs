# Adversarial-Robustness-of-In context learning(ICL)

A collection of papers and resources about adversarial robustness of In context learning(ICL)

With emergence of Large Language models(LLMs), the parameter of the LLMs explosive growth. For instance the Llama2, which is published by Meta, is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Therefore fine tuning LLMs become time and money-consuming. In-context learning(ICL), which don't touch the weight, becomes a powerfult paradigm leveraging LLMs for specific task by utilizing data-label paired examples as demonstrations in the precondition prompts.

# News

# Overview
In this repository, we collect recent advances in safety of LLMs especially for In-Context Learning. 
We hope this repository can help researchers to get better understanding of this promising field.

Table of Contents

Related Surveys
